---
layout: post
use_math: true
title: "Tacotron 논문 정리"
date: 2018-12-11 18:23:10
tagline: "구글에서 개발한 음성합성 모델인 Tacotron을 스터디하여 정리"
categories:
- Speech Synthesis
tags:
- speech
- deep learning
image: /thumbnail-mobile.png
author: "Hyungcheol Noh"
permalink: /2018-12-11-tacotron
---

이번 포스팅은 다음의 논문을 스터디하여 정리하였다:
- [링크1](https://arxiv.org/abs/1703.10135)

## Tacotron?
2018년 구글에서 새로운 TTS 모델인 [Tacotron 2](https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html)를 발표하였다. 구글이 자신들의 블로그에서 주장하기를 거의 사람이 직접 내는 음성과 비슷한 퀄리티의 음성을 생성할 수 있는 모델이라고 홍보하고 있는데 실제로 Tacotron 2가 생성한 음성 샘플을 들어보면 사람의 목소리인지 구분하기 힘들 정도다. Tacotron 2의 음성 샘플은 [링크](https://google.github.io/tacotron/publications/tacotron2/index.html)를 통해서 들어볼 수 있다.

Tacotron 2에 앞서서 먼저 발표된 모델이 2017년에 발표된 Tacotron이다. 저자들은 Tacotron은 이전 TTS 모델들과 비교해서 다음과 같은 장점이 있다고 주장하고 있다.
- 텍스트를 입력으로 받아서 Raw Spectrogram을 바로 생성할 수 있음
- 간단하게 <text, audio> 페어를 이용하여 End-to-End로 학습이 가능함

위와 같은 주장들이 타당성이 있는 이유를 살펴보기 위해서는 기존 모델들의 특징을 한 번 살펴볼 필요가 있다.
